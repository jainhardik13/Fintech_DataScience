{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T06:50:09.611746100Z",
     "start_time": "2026-02-09T06:50:09.573311800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build a tool to scrape the web and extract data from HTML documents.\n",
    "# Web scraping resume from AWS S3 to extract skills section\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n"
   ],
   "id": "f6f2b99433ced98a",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T06:50:13.458952500Z",
     "start_time": "2026-02-09T06:50:09.614745600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Fetch the webpage from S3\n",
    "# Replace with your actual S3 URL\n",
    "# resume_url = \"http://hardik-jain-1837.s3-website-us-east-1.amazonaws.com/\"\n",
    "# resume_url = \"https://krishaggarwal-s3-us-east-1-resume.s3.us-east-1.amazonaws.com/resume.html\"\n",
    "resume_url = input(\"Enter link to resume webpage (S3 URL): \")\n",
    "# e.g., \"https://your-bucket.s3.amazonaws.com/resume.html\"\n",
    "\n",
    "try:\n",
    "    # Send GET request to fetch the webpage\n",
    "    response = requests.get(resume_url)\n",
    "    response.raise_for_status()  # Raise an error for bad status codes\n",
    "\n",
    "    print(f\"Successfully fetched webpage. Status Code: {response.status_code}\")\n",
    "    print(f\"Content Length: {len(response.content)} bytes\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error fetching webpage: {e}\")\n",
    "    response = None\n"
   ],
   "id": "9bca0d2400f1cd4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched webpage. Status Code: 200\n",
      "Content Length: 7149 bytes\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T06:50:13.510022100Z",
     "start_time": "2026-02-09T06:50:13.475393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2: Parse the HTML content\n",
    "if response:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Pretty print the HTML structure (first 1000 characters)\n",
    "    print(\"HTML Structure Preview:\")\n",
    "    print(soup.prettify()[:1000])\n"
   ],
   "id": "efc7c52c41069a83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML Structure Preview:\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Hardik Jain - Resume\n",
      "  </title>\n",
      "  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "  <!-- Fonts -->\n",
      "  <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&amp;family=Georgia&amp;display=swap\" rel=\"stylesheet\"/>\n",
      "  <style>\n",
      "   * {\r\n",
      "            margin: 0;\r\n",
      "            padding: 0;\r\n",
      "            box-sizing: border-box;\r\n",
      "        }\r\n",
      "\r\n",
      "        body {\r\n",
      "            font-family: 'Inter', Arial, sans-serif;\r\n",
      "            background: #f4f4f4;\r\n",
      "            color: #000;\r\n",
      "            padding: 20px;\r\n",
      "            line-height: 1.4;\r\n",
      "        }\r\n",
      "\r\n",
      "        .print-btn {\r\n",
      "            text-align: center;\r\n",
      "            margin-bottom: 15px;\r\n",
      "        }\r\n",
      "\r\n",
      "        .print-btn button {\r\n",
      "            padding: 8px 16px;\r\n",
      "            font-size: 14px;\r\n",
      "            border: 1px solid #000;\r\n",
      "            background: #fff;\r\n",
      "            cursor: pointer;\r\n",
      "        }\r\n",
      "\r\n",
      "        .resume {\r\n",
      "            max-w\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T06:50:13.539181Z",
     "start_time": "2026-02-09T06:50:13.513022200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3: Extract Skills Section\n",
    "# This will try multiple common patterns for skills sections\n",
    "\n",
    "def extract_skills(soup):\n",
    "    \"\"\"\n",
    "    Extract skills from resume webpage using multiple strategies\n",
    "    \"\"\"\n",
    "    skills = []\n",
    "\n",
    "    # Strategy 1: Look for sections with 'skill' in id or class\n",
    "    skills_section = (\n",
    "        soup.find(id=lambda x: x and 'skill' in x.lower()) or\n",
    "        soup.find(class_=lambda x: x and 'skill' in str(x).lower()) or\n",
    "        soup.find('section', class_=lambda x: x and 'skill' in str(x).lower()) or\n",
    "        soup.find('div', class_=lambda x: x and 'skill' in str(x).lower())\n",
    "    )\n",
    "\n",
    "    if skills_section:\n",
    "        print(\"Found skills section using Strategy 1 (id/class matching)\")\n",
    "\n",
    "        # Extract text from list items\n",
    "        list_items = skills_section.find_all(['li', 'span', 'p'])\n",
    "        for item in list_items:\n",
    "            skill_text = item.get_text(strip=True)\n",
    "            if skill_text and len(skill_text) > 0:\n",
    "                skills.append(skill_text)\n",
    "\n",
    "        # If no list items, get all text\n",
    "        if not skills:\n",
    "            skills_text = skills_section.get_text(separator='\\n', strip=True)\n",
    "            skills = [line.strip() for line in skills_text.split('\\n') if line.strip()]\n",
    "\n",
    "    # Strategy 2: Look for headings containing 'skill'\n",
    "    if not skills:\n",
    "        print(\"Trying Strategy 2 (heading-based search)\")\n",
    "        headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "        for heading in headings:\n",
    "            if 'skill' in heading.get_text().lower():\n",
    "                # Get the next sibling elements\n",
    "                next_element = heading.find_next_sibling()\n",
    "                while next_element:\n",
    "                    if next_element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "                        break\n",
    "                    if next_element.name in ['ul', 'ol']:\n",
    "                        list_items = next_element.find_all('li')\n",
    "                        skills.extend([item.get_text(strip=True) for item in list_items])\n",
    "                    elif next_element.name in ['p', 'div']:\n",
    "                        text = next_element.get_text(strip=True)\n",
    "                        if text:\n",
    "                            skills.append(text)\n",
    "                    next_element = next_element.find_next_sibling()\n",
    "                if skills:\n",
    "                    break\n",
    "\n",
    "    # Strategy 3: Search for all lists and filter\n",
    "    if not skills:\n",
    "        print(\"Trying Strategy 3 (comprehensive list search)\")\n",
    "        all_lists = soup.find_all(['ul', 'ol'])\n",
    "        for lst in all_lists:\n",
    "            # Check if parent or previous sibling mentions skills\n",
    "            context = \"\"\n",
    "            if lst.find_previous(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "                context = lst.find_previous(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']).get_text().lower()\n",
    "\n",
    "            if 'skill' in context:\n",
    "                list_items = lst.find_all('li')\n",
    "                skills.extend([item.get_text(strip=True) for item in list_items])\n",
    "                break\n",
    "\n",
    "    return skills\n"
   ],
   "id": "20c0dd999395e595",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T06:50:13.563336800Z",
     "start_time": "2026-02-09T06:50:13.540181100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 4: Execute extraction and display results\n",
    "if response:\n",
    "    extracted_skills = extract_skills(soup)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXTRACTED SKILLS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    if extracted_skills:\n",
    "        for idx, skill in enumerate(extracted_skills, 1):\n",
    "            print(f\"{idx}. {skill}\")\n",
    "\n",
    "        print(f\"\\nTotal skills found: {len(extracted_skills)}\")\n",
    "    else:\n",
    "        print(\"No skills found. The HTML structure might be different.\")\n",
    "        print(\"\\nTip: Inspect the HTML structure manually to identify the skills section.\")\n",
    "        print(\"You can view the full HTML by uncommenting the line below:\")\n",
    "        print(\"# print(soup.prettify())\")\n",
    "\n",
    "    print(\"=\"*50)\n"
   ],
   "id": "b26912bdcdff5066",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found skills section using Strategy 1 (id/class matching)\n",
      "\n",
      "==================================================\n",
      "EXTRACTED SKILLS\n",
      "==================================================\n",
      "1. Languages:Java, C++, Python, JavaScript\n",
      "2. Backend:Spring Boot, REST APIs, Microservices, JWT\n",
      "3. Databases:MySQL, MongoDB, PostgreSQL (basic)\n",
      "4. Core CS:DSA, OS, DBMS, Computer Networks\n",
      "5. Tools:Git, Docker (basic), AWS EC2/S3 (beginner), Linux\n",
      "6. Soft Skills:Problem Solving, Team Collaboration, Fast Learner\n",
      "\n",
      "Total skills found: 6\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T06:50:13.588568700Z",
     "start_time": "2026-02-09T06:50:13.565336800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 5: Save skills to a CSV file\n",
    "if response and extracted_skills:\n",
    "    # Create a DataFrame\n",
    "    skills_df = pd.DataFrame({\n",
    "        'Skill_Number': range(1, len(extracted_skills) + 1),\n",
    "        'Skill': extracted_skills\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    output_file = 'extracted_skills.csv'\n",
    "    skills_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nSkills saved to: {output_file}\")\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(\"\\nSkills DataFrame:\")\n",
    "    print(skills_df)\n"
   ],
   "id": "8f8fd369d85099a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skills saved to: extracted_skills.csv\n",
      "\n",
      "Skills DataFrame:\n",
      "   Skill_Number                                              Skill\n",
      "0             1            Languages:Java, C++, Python, JavaScript\n",
      "1             2  Backend:Spring Boot, REST APIs, Microservices,...\n",
      "2             3       Databases:MySQL, MongoDB, PostgreSQL (basic)\n",
      "3             4           Core CS:DSA, OS, DBMS, Computer Networks\n",
      "4             5  Tools:Git, Docker (basic), AWS EC2/S3 (beginne...\n",
      "5             6  Soft Skills:Problem Solving, Team Collaboratio...\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T06:50:13.601279200Z",
     "start_time": "2026-02-09T06:50:13.591447900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 6: Advanced extraction - Get all sections\n",
    "def extract_all_sections(soup):\n",
    "    \"\"\"\n",
    "    Extract all major sections from the resume\n",
    "    \"\"\"\n",
    "    sections = {}\n",
    "\n",
    "    # Find all headings\n",
    "    headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "    for heading in headings:\n",
    "        section_title = heading.get_text(strip=True)\n",
    "        section_content = []\n",
    "\n",
    "        # Get content until next heading\n",
    "        next_element = heading.find_next_sibling()\n",
    "        while next_element and next_element.name not in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "            text = next_element.get_text(strip=True)\n",
    "            if text:\n",
    "                section_content.append(text)\n",
    "            next_element = next_element.find_next_sibling()\n",
    "\n",
    "        if section_content:\n",
    "            sections[section_title] = section_content\n",
    "\n",
    "    return sections\n"
   ],
   "id": "bbb311a9051bc230",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T06:50:13.626539300Z",
     "start_time": "2026-02-09T06:50:13.602278200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optional: Extract all sections for complete resume data\n",
    "if response:\n",
    "    all_sections = extract_all_sections(soup)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ALL RESUME SECTIONS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    for section_title, content in all_sections.items():\n",
    "        print(f\"\\n### {section_title} ###\")\n",
    "        for item in content:\n",
    "            print(f\"  - {item}\")\n",
    "\n",
    "    print(\"=\"*50)\n",
    "\n"
   ],
   "id": "cb6f1e46106d0f52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ALL RESUME SECTIONS\n",
      "==================================================\n",
      "\n",
      "### Hardik Jain ###\n",
      "  - jainhardik2100@gmail.com | 9115633911 |linkedin.com/in/jainhardik21|github.com/jainhardik13\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
